import json
import logging
from chatbot.models import Chat
from core.models import Paciente
from chatbot.models import EncuestaSatisfaccion
from .AI_Client import client
from .trascript_history import transcript_history
from .default_chat import default_chat

logger = logging.getLogger(__name__)


def esperando_encuesta(messages, chat: Chat, instance: str):
    """
    Analyzes the patient's survey response to extract sentiment and actionable insights.
    """
    # 1. Get the text context
    transcription, history = transcript_history(messages)

    # 2. Identify the patient (Crucial for linking data)
    # We assume the chat is linked to a phone, and we find the patient by that phone.
    # Adjust this logic based on how you link Chats to Patients in your system.
    phone_number = chat.phone_number # Assuming your Chat model has the phone number
    try:
        # We strip the '+' or standardizing logic you use
        clean_phone = phone_number.replace('+', '').strip()
        paciente = Paciente.objects.filter(telefono__icontains=clean_phone).first()
    except Exception:
        paciente = None

    # 3. Define the AI Prompt for Business Intelligence
    prompt = f"""
    You are a Data Analyst for a Dental Clinic. You are analyzing a response from a patient to a satisfaction survey.

    The survey asked 3 things:
    1. What they valued most.
    2. What could be improved.
    3. Suggestions.

    Your task is to analyze the user's input and extract structured data in JSON format.

    ### output_format:
    {{
        "sentiment": "POSITIVE" | "NEUTRAL" | "NEGATIVE",
        "aspectos_positivos": ["list", "of", "things", "liked"],
        "areas_mejora": ["list", "of", "complaints", "or", "improvements"],
        "sugerencias": "Summary of any specific suggestion",
        "requiere_atencion_humana": boolean, // Set TRUE if user is angry, mentions pain, medical issues, or specifically asks for a call.
        "response_message": "string" // Generate a polite, empathetic, short response in Spanish based on their sentiment.
        "change_logic" : boolean
    }}

    ### Rules for 'response_message':
    - If POSITIVE: Thank them warmly and say we are happy to serve them.
    - If NEGATIVE/IMPROVEMENT: Thank them for their honesty, apologize if needed, and say we will take this into account to improve.
    - Keep it short and natural (WhatsApp style).
    - In case the user anwsers something unrelated to the questions, like asking for scheduling an apointment return the change_logic value as true, so the system can answer the user coherently

    ### Input Text (Patient Response):
    "{transcription}"
    """

    try:
        # 4. Call LLM
        response = client.chat.completions.create(
            model="deepseek-chat", # or gpt-4o-mini / gpt-3.5-turbo
            messages=[{"role": "user", "content": prompt}],
            max_tokens=350,
            temperature=0.5,
            response_format={"type": "json_object"},
        )

        data = json.loads(response.choices[0].message.content)

        if data.get('change_logic', False):
        # If the user response indicates a change in logic (e.g., wants to schedule an appointment)
            chat.current_state = "default"
            chat.save()
            return default_chat(messages, chat)

        # 5. Save Data (Making the $73 worth it)
        if paciente:
            EncuestaSatisfaccion.objects.create(
                paciente=paciente,
                texto_original=transcription,
                sentimiento=data.get('sentiment', 'NEUTRAL'),
                aspectos_positivos=json.dumps(data.get('aspectos_positivos', [])),
                areas_mejora=json.dumps(data.get('areas_mejora', [])),
                sugerencias=data.get('sugerencias', ''),
                requiere_atencion_humana=data.get('requiere_atencion_humana', False)
            )
            
            # OPTIONAL: Send internal alert if 'requiere_atencion_humana' is True
            if data.get('requiere_atencion_humana'):
                logger.warning(f"URGENT FEEDBACK from {paciente}: {transcription}")
                # Trigger a Telegram alert to your admin group here if you want

        # 6. Update State
        chat.current_state = "default"
        chat.save()

        # 7. Return the dynamic response generated by AI
        return data.get('response_message', "¡Muchas gracias por sus comentarios! Nos ayudan mucho a mejorar.")

    except Exception as e:
        logger.error(f"Error processing survey: {e}")
        # Fallback in case AI fails
        chat.current_state = "default"
        chat.save()
        return "¡Muchas gracias por su respuesta! La hemos registrado correctamente."